{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 468 files belonging to 2 classes.\n",
      "Using 422 files for training.\n",
      "Found 112 files belonging to 2 classes.\n",
      "Using 11 files for validation.\n",
      "Epoch 1/25\n",
      "43/43 [==============================] - 14s 293ms/step - loss: 5.5839 - accuracy: 0.5261 - val_loss: 0.6589 - val_accuracy: 0.6364\n",
      "Epoch 2/25\n",
      "43/43 [==============================] - 12s 285ms/step - loss: 1.2310 - accuracy: 0.5355 - val_loss: 0.6896 - val_accuracy: 0.7273\n",
      "Epoch 3/25\n",
      "43/43 [==============================] - 12s 268ms/step - loss: 0.9057 - accuracy: 0.5948 - val_loss: 0.5152 - val_accuracy: 0.8182\n",
      "Epoch 4/25\n",
      "43/43 [==============================] - 12s 286ms/step - loss: 0.6824 - accuracy: 0.6967 - val_loss: 0.5751 - val_accuracy: 0.7273\n",
      "Epoch 5/25\n",
      "43/43 [==============================] - 12s 272ms/step - loss: 0.5706 - accuracy: 0.7417 - val_loss: 0.4926 - val_accuracy: 0.7273\n",
      "Epoch 6/25\n",
      "43/43 [==============================] - 12s 269ms/step - loss: 0.5141 - accuracy: 0.7725 - val_loss: 0.8199 - val_accuracy: 0.7273\n",
      "Epoch 7/25\n",
      "43/43 [==============================] - 12s 288ms/step - loss: 0.5433 - accuracy: 0.7678 - val_loss: 0.5631 - val_accuracy: 0.7273\n",
      "Epoch 8/25\n",
      "43/43 [==============================] - 12s 277ms/step - loss: 0.4230 - accuracy: 0.8152 - val_loss: 0.8774 - val_accuracy: 0.5455\n",
      "Epoch 9/25\n",
      "43/43 [==============================] - 12s 269ms/step - loss: 0.4315 - accuracy: 0.8246 - val_loss: 0.8454 - val_accuracy: 0.4545\n",
      "Epoch 10/25\n",
      "43/43 [==============================] - 11s 266ms/step - loss: 0.3667 - accuracy: 0.8673 - val_loss: 0.3802 - val_accuracy: 0.9091\n",
      "Epoch 11/25\n",
      "43/43 [==============================] - 13s 311ms/step - loss: 0.3455 - accuracy: 0.8602 - val_loss: 0.7205 - val_accuracy: 0.5455\n",
      "Epoch 12/25\n",
      "43/43 [==============================] - 17s 405ms/step - loss: 0.2812 - accuracy: 0.8863 - val_loss: 0.3789 - val_accuracy: 0.8182\n",
      "Epoch 13/25\n",
      "43/43 [==============================] - 16s 352ms/step - loss: 0.2548 - accuracy: 0.8957 - val_loss: 1.5057 - val_accuracy: 0.7273\n",
      "Epoch 14/25\n",
      "43/43 [==============================] - 12s 267ms/step - loss: 0.2260 - accuracy: 0.9028 - val_loss: 0.6428 - val_accuracy: 0.7273\n",
      "Epoch 15/25\n",
      "43/43 [==============================] - 12s 281ms/step - loss: 0.2249 - accuracy: 0.9194 - val_loss: 0.2582 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "43/43 [==============================] - 11s 251ms/step - loss: 0.1832 - accuracy: 0.9336 - val_loss: 0.9829 - val_accuracy: 0.7273\n",
      "Epoch 17/25\n",
      "43/43 [==============================] - 11s 245ms/step - loss: 0.1992 - accuracy: 0.9336 - val_loss: 6.3250 - val_accuracy: 0.4545\n",
      "Epoch 18/25\n",
      "43/43 [==============================] - 11s 261ms/step - loss: 0.1684 - accuracy: 0.9408 - val_loss: 2.0137 - val_accuracy: 0.3636\n",
      "Epoch 19/25\n",
      "43/43 [==============================] - 11s 260ms/step - loss: 0.1433 - accuracy: 0.9408 - val_loss: 0.2925 - val_accuracy: 0.8182\n",
      "Epoch 20/25\n",
      "43/43 [==============================] - 11s 250ms/step - loss: 0.1367 - accuracy: 0.9597 - val_loss: 0.4093 - val_accuracy: 0.7273\n",
      "Epoch 21/25\n",
      "43/43 [==============================] - 12s 284ms/step - loss: 0.0992 - accuracy: 0.9621 - val_loss: 0.2743 - val_accuracy: 0.9091\n",
      "Epoch 22/25\n",
      "43/43 [==============================] - 12s 276ms/step - loss: 0.0659 - accuracy: 0.9810 - val_loss: 0.3552 - val_accuracy: 0.8182\n",
      "Epoch 23/25\n",
      "43/43 [==============================] - 14s 317ms/step - loss: 0.0616 - accuracy: 0.9716 - val_loss: 0.6453 - val_accuracy: 0.6364\n",
      "Epoch 24/25\n",
      "43/43 [==============================] - 12s 268ms/step - loss: 0.1615 - accuracy: 0.9573 - val_loss: 0.2908 - val_accuracy: 0.9091\n",
      "Epoch 25/25\n",
      "43/43 [==============================] - 11s 259ms/step - loss: 0.0625 - accuracy: 0.9858 - val_loss: 0.3092 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'converters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 110\u001b[0m\n\u001b[0;32m    108\u001b[0m model\u001b[39m.\u001b[39mfit(train_datagen,epochs\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m,validation_data\u001b[39m=\u001b[39mtest_datagen,validation_steps\u001b[39m=\u001b[39m\u001b[39m35\u001b[39m\u001b[39m/\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[39m# model.save('cat.model(newOptimiser2)')\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m tf\u001b[39m.\u001b[39;49mconverters\u001b[39m.\u001b[39msave_keras_model(model, \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'converters'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "DIRECTORY = r'D:\\Desktop\\Cat_model\\dataset\\train'\n",
    "CATEGORIES = [\"Earmites\",\"Ringworm\"]\n",
    "\n",
    "IMG_SIZE = 130\n",
    "\n",
    "data = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    folder = os.path.join(DIRECTORY, category)\n",
    "    label = CATEGORIES.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n",
    "        data.append([img_arr, label])\n",
    "random.shuffle(data)\n",
    "\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for features, labels in data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# y = to_categorical(y)\n",
    "#create a linear stack of layers\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 32 filters, a 3x3 kernel, and ReLU activation\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(130, 130, 3)))\n",
    "\n",
    "# Add a max pooling layer with a 2x2 pool size to reduce spatial dimensionality of the output\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a flatten layer to convert the 2D feature maps to a 1D feature vector \n",
    "# that can be processed by the fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add a dense layer with 128 neurons and ReLU activation\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#to prevent overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Add an output layer with 2 neurons and a softmax activation\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "#RMSprop optimization algorithm for deep learning models\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "#used for multi-class classification problems.\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "base_dir = 'dataset'\n",
    "\n",
    "train_datagen = image_dataset_from_directory(base_dir+\"/train\",\n",
    "                                                  image_size=(130,130),\n",
    "                                                  subset='training',\n",
    "                                                  seed = 1,\n",
    "                                                 validation_split=0.1,\n",
    "                                                  batch_size= 10,\n",
    "                                                  label_mode='categorical')\n",
    "test_datagen = image_dataset_from_directory(base_dir+\"/test\",\n",
    "                                                  image_size=(130,130),\n",
    "                                                  subset='validation',\n",
    "                                                  seed = 1,\n",
    "                                                 validation_split=0.1,\n",
    "                                                  batch_size= 10,\n",
    "                                                  label_mode='categorical')\n",
    "\n",
    "model.fit(train_datagen,epochs=25,validation_data=test_datagen,validation_steps=35/32)\n",
    "model.save('cat.model(newOptimiser2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5601117e-05 9.9998438e-01]]\n",
      "Ringworm\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('cat.model(newOptimiser2)')\n",
    "\n",
    "# Load the image you want to classify\n",
    "img = cv2.imread(r'dataset\\test\\Ringworm\\Ringworm-cat-Handsome-5680LF_1_jpg.rf.8f5acea6a261fc1720135f31c6f960cc.jpg')\n",
    "img = cv2.resize(img, (130, 130))\n",
    "img = np.reshape(img, [1, 130, 130, 3])\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "print(prediction)\n",
    "if prediction[0][0] > prediction[0][1]:\n",
    "    print(\"Earmites\")\n",
    "else:\n",
    "    print(\"Ringworm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 files belonging to 2 classes.\n",
      "Using 100 files for validation.\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 2.0770 - accuracy: 0.7700\n",
      "Test accuracy: 0.7699999809265137\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.models import load_model\n",
    "base_dir = 'dataset'\n",
    "model = load_model('cat.model(newOptimiser2)')\n",
    "test_data = image_dataset_from_directory(base_dir+\"/test\",\n",
    "                                        #   image_size=(130,130),\n",
    "                                          subset='validation',\n",
    "                                          seed = 1,\n",
    "                                          validation_split=0.9,\n",
    "                                          batch_size= 10,\n",
    "                                          label_mode='categorical'\n",
    "                )\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faee8b4212e6789382cf0558b2c237e413721f41f0d22c178535599a903395af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
