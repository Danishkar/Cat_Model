{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 468 files belonging to 2 classes.\n",
      "Using 422 files for training.\n",
      "Found 112 files belonging to 2 classes.\n",
      "Using 11 files for validation.\n",
      "Epoch 1/25\n",
      "43/43 [==============================] - 15s 335ms/step - loss: 14.3630 - accuracy: 0.5758 - val_loss: 0.6208 - val_accuracy: 0.6364\n",
      "Epoch 2/25\n",
      "43/43 [==============================] - 13s 312ms/step - loss: 0.5078 - accuracy: 0.7464 - val_loss: 0.5435 - val_accuracy: 0.7273\n",
      "Epoch 3/25\n",
      "43/43 [==============================] - 12s 281ms/step - loss: 0.4346 - accuracy: 0.7962 - val_loss: 0.6049 - val_accuracy: 0.8182\n",
      "Epoch 4/25\n",
      "43/43 [==============================] - 13s 294ms/step - loss: 0.3442 - accuracy: 0.8365 - val_loss: 0.4373 - val_accuracy: 0.9091\n",
      "Epoch 5/25\n",
      "43/43 [==============================] - 13s 306ms/step - loss: 0.3843 - accuracy: 0.8365 - val_loss: 0.7423 - val_accuracy: 0.4545\n",
      "Epoch 6/25\n",
      "43/43 [==============================] - 17s 393ms/step - loss: 0.2821 - accuracy: 0.8531 - val_loss: 0.4549 - val_accuracy: 0.6364\n",
      "Epoch 7/25\n",
      "43/43 [==============================] - 12s 266ms/step - loss: 0.2900 - accuracy: 0.8720 - val_loss: 0.7806 - val_accuracy: 0.6364\n",
      "Epoch 8/25\n",
      "43/43 [==============================] - 12s 267ms/step - loss: 0.4345 - accuracy: 0.8365 - val_loss: 0.6078 - val_accuracy: 0.6364\n",
      "Epoch 9/25\n",
      "43/43 [==============================] - 12s 268ms/step - loss: 0.4035 - accuracy: 0.8128 - val_loss: 0.5586 - val_accuracy: 0.6364\n",
      "Epoch 10/25\n",
      "43/43 [==============================] - 12s 269ms/step - loss: 0.3759 - accuracy: 0.8294 - val_loss: 0.9512 - val_accuracy: 0.3636\n",
      "Epoch 11/25\n",
      "43/43 [==============================] - 12s 283ms/step - loss: 0.2798 - accuracy: 0.8791 - val_loss: 0.7817 - val_accuracy: 0.4545\n",
      "Epoch 12/25\n",
      "43/43 [==============================] - 12s 272ms/step - loss: 0.4478 - accuracy: 0.8152 - val_loss: 0.6543 - val_accuracy: 0.5455\n",
      "Epoch 13/25\n",
      "43/43 [==============================] - 12s 274ms/step - loss: 0.2822 - accuracy: 0.8768 - val_loss: 0.4756 - val_accuracy: 0.6364\n",
      "Epoch 14/25\n",
      "43/43 [==============================] - 12s 276ms/step - loss: 0.2619 - accuracy: 0.8555 - val_loss: 0.5491 - val_accuracy: 0.7273\n",
      "Epoch 15/25\n",
      "43/43 [==============================] - 12s 267ms/step - loss: 0.1762 - accuracy: 0.9194 - val_loss: 0.4199 - val_accuracy: 0.7273\n",
      "Epoch 16/25\n",
      "43/43 [==============================] - 12s 269ms/step - loss: 0.1915 - accuracy: 0.9218 - val_loss: 0.4441 - val_accuracy: 0.9091\n",
      "Epoch 17/25\n",
      "43/43 [==============================] - 12s 269ms/step - loss: 0.3163 - accuracy: 0.8626 - val_loss: 0.6598 - val_accuracy: 0.4545\n",
      "Epoch 18/25\n",
      "43/43 [==============================] - 11s 264ms/step - loss: 0.2682 - accuracy: 0.9289 - val_loss: 0.5504 - val_accuracy: 0.5455\n",
      "Epoch 19/25\n",
      "43/43 [==============================] - 12s 266ms/step - loss: 0.4906 - accuracy: 0.8626 - val_loss: 0.4496 - val_accuracy: 0.8182\n",
      "Epoch 20/25\n",
      "43/43 [==============================] - 11s 266ms/step - loss: 0.2512 - accuracy: 0.8934 - val_loss: 0.3699 - val_accuracy: 0.6364\n",
      "Epoch 21/25\n",
      "43/43 [==============================] - 11s 265ms/step - loss: 0.1507 - accuracy: 0.9360 - val_loss: 0.3653 - val_accuracy: 0.6364\n",
      "Epoch 22/25\n",
      "43/43 [==============================] - 11s 266ms/step - loss: 0.1588 - accuracy: 0.9431 - val_loss: 0.3855 - val_accuracy: 0.8182\n",
      "Epoch 23/25\n",
      "43/43 [==============================] - 11s 265ms/step - loss: 0.1443 - accuracy: 0.9479 - val_loss: 0.4956 - val_accuracy: 0.7273\n",
      "Epoch 24/25\n",
      "43/43 [==============================] - 11s 262ms/step - loss: 0.1297 - accuracy: 0.9526 - val_loss: 0.2815 - val_accuracy: 0.8182\n",
      "Epoch 25/25\n",
      "43/43 [==============================] - 12s 269ms/step - loss: 0.0906 - accuracy: 0.9645 - val_loss: 0.3565 - val_accuracy: 0.7273\n",
      "INFO:tensorflow:Assets written to: cat.model(newOptimiser1testing)\\assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "DIRECTORY = r'D:\\Desktop\\Cat_model\\dataset\\train'\n",
    "CATEGORIES = [\"Earmites\",\"Ringworm\"]\n",
    "\n",
    "IMG_SIZE = 130\n",
    "\n",
    "data = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    folder = os.path.join(DIRECTORY, category)\n",
    "    label = CATEGORIES.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n",
    "        data.append([img_arr, label])\n",
    "random.shuffle(data)\n",
    "\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for features, labels in data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "y = keras.utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 32 filters, a 3x3 kernel, and ReLU activation\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(130, 130, 3)))\n",
    "\n",
    "# Add a max pooling layer with a 2x2 pool size\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a flatten layer to convert the 2D feature maps to a 1D feature vector\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Add a dense layer with 128 neurons and ReLU activation\n",
    "\n",
    "# Add an output layer with 2 neurons and a softmax activation\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss and the Adam optimizer\n",
    "# opt = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "base_dir = 'dataset'\n",
    "\n",
    "train_datagen = image_dataset_from_directory(base_dir+\"/train\",\n",
    "                                                  image_size=(130,130),\n",
    "                                                  subset='training',\n",
    "                                                  seed = 1,\n",
    "                                                 validation_split=0.1,\n",
    "                                                  batch_size= 10,\n",
    "                                                  label_mode='categorical'\n",
    "                                                  )\n",
    "test_datagen = image_dataset_from_directory(base_dir+\"/test\",\n",
    "                                                  image_size=(130,130),\n",
    "                                                  subset='validation',\n",
    "                                                  seed = 1,\n",
    "                                                 validation_split=0.1,\n",
    "                                                  batch_size= 10,\n",
    "                                                  label_mode='categorical')\n",
    "\n",
    "model.fit(train_datagen,epochs=25,validation_data=test_datagen,validation_steps=2)\n",
    "model.save('cat.model(newOptimiser1testing)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.47432312 0.52567685]]\n",
      "The image is a dog\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('cat.model(newOptimiser1testing)')\n",
    "\n",
    "# Load a single image to test\n",
    "img_path = 'D:\\\\Downloads\\\\download3.jfif'\n",
    "img = image.load_img(img_path, target_size=(130, 130))\n",
    "\n",
    "# Convert the image to a numpy array and preprocess it\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x /= 255.0\n",
    "\n",
    "# Make a prediction using the loaded model\n",
    "pred = model.predict(x)\n",
    "print(pred)\n",
    "if pred[0][0] > pred[0][1]:\n",
    "    print('The image is a cat')\n",
    "else:\n",
    "    print('The image is a dog')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 files belonging to 2 classes.\n",
      "Using 100 files for validation.\n",
      "10/10 [==============================] - 2s 62ms/step - loss: 2.7363 - accuracy: 0.7200\n",
      "Test accuracy: 0.7200000286102295\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.models import load_model\n",
    "base_dir = 'dataset'\n",
    "model = load_model('cat.model(newOptimiser1)')\n",
    "test_data = image_dataset_from_directory(base_dir+\"/test\",\n",
    "                                          image_size=(130,130),\n",
    "                                          subset='validation',\n",
    "                                          seed = 1,\n",
    "                                          validation_split=0.9,\n",
    "                                          batch_size= 10,\n",
    "                )\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_data)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faee8b4212e6789382cf0558b2c237e413721f41f0d22c178535599a903395af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
