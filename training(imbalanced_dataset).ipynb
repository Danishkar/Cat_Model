{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1026 files belonging to 2 classes.\n",
      "Using 924 files for training.\n",
      "Found 112 files belonging to 2 classes.\n",
      "Using 11 files for validation.\n",
      "Epoch 1/25\n",
      "93/93 [==============================] - 61s 542ms/step - loss: 32.4020 - accuracy: 0.7435 - val_loss: 17.0427 - val_accuracy: 0.6364\n",
      "Epoch 2/25\n",
      "93/93 [==============================] - 44s 469ms/step - loss: 3.0935 - accuracy: 0.8561 - val_loss: 18.3520 - val_accuracy: 0.6364\n",
      "Epoch 3/25\n",
      "93/93 [==============================] - 44s 472ms/step - loss: 1.2746 - accuracy: 0.9134 - val_loss: 2.4007 - val_accuracy: 0.5455\n",
      "Epoch 4/25\n",
      "93/93 [==============================] - 44s 474ms/step - loss: 0.5003 - accuracy: 0.9361 - val_loss: 3.7730 - val_accuracy: 0.6364\n",
      "Epoch 5/25\n",
      "93/93 [==============================] - 46s 493ms/step - loss: 0.5361 - accuracy: 0.9481 - val_loss: 2.2344 - val_accuracy: 0.7273\n",
      "Epoch 6/25\n",
      "93/93 [==============================] - 47s 504ms/step - loss: 0.3367 - accuracy: 0.9665 - val_loss: 3.3279 - val_accuracy: 0.4545\n",
      "Epoch 7/25\n",
      "93/93 [==============================] - 45s 489ms/step - loss: 0.1645 - accuracy: 0.9827 - val_loss: 1.9294 - val_accuracy: 0.8182\n",
      "Epoch 8/25\n",
      "93/93 [==============================] - 45s 485ms/step - loss: 0.1515 - accuracy: 0.9784 - val_loss: 6.9785 - val_accuracy: 0.4545\n",
      "Epoch 9/25\n",
      "93/93 [==============================] - 45s 481ms/step - loss: 0.0936 - accuracy: 0.9913 - val_loss: 6.8658 - val_accuracy: 0.4545\n",
      "Epoch 10/25\n",
      "93/93 [==============================] - 45s 482ms/step - loss: 0.0395 - accuracy: 0.9913 - val_loss: 6.2643 - val_accuracy: 0.4545\n",
      "Epoch 11/25\n",
      "93/93 [==============================] - 44s 476ms/step - loss: 0.0243 - accuracy: 0.9978 - val_loss: 8.8334 - val_accuracy: 0.4545\n",
      "Epoch 12/25\n",
      "93/93 [==============================] - 45s 479ms/step - loss: 0.0356 - accuracy: 0.9946 - val_loss: 4.0353 - val_accuracy: 0.4545\n",
      "Epoch 13/25\n",
      "93/93 [==============================] - 49s 525ms/step - loss: 2.9031e-07 - accuracy: 1.0000 - val_loss: 6.3542 - val_accuracy: 0.4545\n",
      "Epoch 14/25\n",
      "93/93 [==============================] - 50s 541ms/step - loss: 0.0432 - accuracy: 0.9978 - val_loss: 4.9973 - val_accuracy: 0.5455\n",
      "Epoch 15/25\n",
      "93/93 [==============================] - 44s 470ms/step - loss: 2.8757e-08 - accuracy: 1.0000 - val_loss: 9.3763 - val_accuracy: 0.4545\n",
      "Epoch 16/25\n",
      "93/93 [==============================] - 43s 464ms/step - loss: 0.0462 - accuracy: 0.9957 - val_loss: 3.7152 - val_accuracy: 0.5455\n",
      "Epoch 17/25\n",
      "93/93 [==============================] - 44s 469ms/step - loss: 1.0237e-05 - accuracy: 1.0000 - val_loss: 6.6745 - val_accuracy: 0.4545\n",
      "Epoch 18/25\n",
      "93/93 [==============================] - 44s 477ms/step - loss: 1.9793e-08 - accuracy: 1.0000 - val_loss: 6.7914 - val_accuracy: 0.4545\n",
      "Epoch 19/25\n",
      "93/93 [==============================] - 45s 480ms/step - loss: 0.0129 - accuracy: 0.9989 - val_loss: 6.3857 - val_accuracy: 0.5455\n",
      "Epoch 20/25\n",
      "93/93 [==============================] - 44s 475ms/step - loss: 0.0401 - accuracy: 0.9957 - val_loss: 5.1966 - val_accuracy: 0.5455\n",
      "Epoch 21/25\n",
      "93/93 [==============================] - 46s 494ms/step - loss: 7.3973e-06 - accuracy: 1.0000 - val_loss: 4.5962 - val_accuracy: 0.6364\n",
      "Epoch 22/25\n",
      "93/93 [==============================] - 48s 517ms/step - loss: 7.7217e-08 - accuracy: 1.0000 - val_loss: 6.3941 - val_accuracy: 0.5455\n",
      "Epoch 23/25\n",
      "93/93 [==============================] - 46s 491ms/step - loss: 1.6409e-09 - accuracy: 1.0000 - val_loss: 5.2788 - val_accuracy: 0.6364\n",
      "Epoch 24/25\n",
      "93/93 [==============================] - 44s 471ms/step - loss: 2.0123e-09 - accuracy: 1.0000 - val_loss: 6.4588 - val_accuracy: 0.5455\n",
      "Epoch 25/25\n",
      "93/93 [==============================] - 44s 477ms/step - loss: 1.8983e-10 - accuracy: 1.0000 - val_loss: 4.5196 - val_accuracy: 0.6364\n",
      "INFO:tensorflow:Assets written to: cat.model(imbalanced_dataset_newOptimiser)\\assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "DIRECTORY = r'D:\\Desktop\\Cat_model\\dataset2\\train'\n",
    "CATEGORIES = [\"Earmites\",\"Ringworm\"]\n",
    "\n",
    "IMG_SIZE = 150\n",
    "\n",
    "data = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    folder = os.path.join(DIRECTORY, category)\n",
    "    label = CATEGORIES.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = cv2.resize(img_arr, (IMG_SIZE, IMG_SIZE))\n",
    "        data.append([img_arr, label])\n",
    "random.shuffle(data)\n",
    "\n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for features, labels in data:\n",
    "    X.append(features)\n",
    "    y.append(labels)\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# y = to_categorical(y)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 32 filters, a 3x3 kernel, and ReLU activation\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "\n",
    "# Add a max pooling layer with a 2x2 pool size\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a flatten layer to convert the 2D feature maps to a 1D feature vector\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 128 neurons and ReLU activation\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Add an output layer with 2 neurons and a softmax activation\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and the Adam optimizer\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "base_dir = 'dataset2'\n",
    "\n",
    "train_datagen = image_dataset_from_directory(base_dir+\"/train\",\n",
    "                                                  image_size=(150,150),\n",
    "                                                  subset='training',\n",
    "                                                  seed = 1,\n",
    "                                                 validation_split=0.1,\n",
    "                                                  batch_size= 10)\n",
    "test_datagen = image_dataset_from_directory(base_dir+\"/test\",\n",
    "                                                  image_size=(150,150),\n",
    "                                                  subset='validation',\n",
    "                                                  seed = 1,\n",
    "                                                 validation_split=0.1,\n",
    "                                                  batch_size= 10)\n",
    "\n",
    "model.fit(train_datagen,epochs=25,validation_data=test_datagen)\n",
    "model.save('cat.model(imbalanced_dataset_newOptimiser)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020A025F6290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[1.]]\n",
      "Ringworm\n",
      "probability 1.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('cat.model(imbalanced_dataset)')\n",
    "\n",
    "# Load the image you want to classify\n",
    "img = cv2.imread(r'D:\\Downloads\\download3.jfif')\n",
    "img = cv2.resize(img, (150, 150))\n",
    "img = np.reshape(img, [1, 150, 150, 3])\n",
    "\n",
    "prediction = model.predict(img)\n",
    "\n",
    "print(prediction)\n",
    "if (prediction >= 0.5):\n",
    "    print(\"Ringworm\")\n",
    "    print(\"probability \"+ str(prediction[0][0]))\n",
    "else:\n",
    "    print(\"Earmites\")\n",
    "    print(\"probability \"+ str(1 - prediction[0][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faee8b4212e6789382cf0558b2c237e413721f41f0d22c178535599a903395af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
